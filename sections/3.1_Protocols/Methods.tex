\subsection{Methods}
\label{Protocols_Methods}

The implemented pipeline consists of 10 distinct steps to process, harmonize and integrate bioactivity data into the CC universe of small molecule signatures. Steps 1-3 are preliminary and identical across all presented tasks. Steps 4-10 are generally common to all tasks but require slight fine-tuning to specify the location of the input data and the name of the new CC bioactivity space.

\paragraph{1. Setting up the CC environment} \leavevmode

The installation of the CC in a local computer is carried out following the instructions provided in: \\

\begin{lstlisting}
https://gitlabsbnb.irbbarcelona.org/packages/chemical_checker/-/tree/master
\end{lstlisting}

In short, we need to i) install Singularity (version>3.6), ii) clone the CC repository to a local directory and iii) run the setup script (\textit{sudo} permissions are needed). After that, we need to iv) adapt the CC configuration file to fit the user’s CC environment and, finally, v) clone the CC protocols repository to implement the work described in this article.

i) Install Singularity: \\

\begin{lstlisting}
$ sudo apt-get update && sudo apt-get install -y \
     build-essential \
     uuid-dev \
     libgpgme-dev \
     squashfs-tools \
     libseccomp-dev \
     wget \
     pkg-config \
     git \
     cryptsetup-bin\
     golang-go

 $ export VERSION=3.8.0 && # adjust this as necessary \
     wget https://github.com/sylabs/singularity/releases/download/v${VERSION}/singularity-ce-${VERSION}.tar.gz && \
     tar -xzf singularity-ce-${VERSION}.tar.gz && \
     cd singularity-ce-${VERSION}

 $ ./mconfig && \
     make -C ./builddir && \
     sudo make -C ./builddir install
\end{lstlisting}

ii) Cloning the CC repository to a local directory named \textit{PATH\_TO\_CC}: \\

\begin{lstlisting}
mkdir -p <PATH_TO_CC> && cd <PATH_TO_CC>
git clone http://gitlabsbnb.irbbarcelona.org/packages/chemical_checker.git
\end{lstlisting}

iii) Running the setup script:  \\

\begin{lstlisting}
cd chemical_checker && sh setup/setup_chemicalchecker.sh
\end{lstlisting}

iv) Manually editing the CC configuration file located at \textit{PATH\_TO\_CC/chemical\_checker/setup/cc\_config.json}, referred to as \textit{PATH\_TO\_CC\_CONFIG}. In this file, the user must specify the variables \textit{SINGULARITY\_IMAGE}, \textit{CC\_REPO} and \textit{CC\_TMP}.
\begin{itemize}
    \item \textit{SINGULARITY\_IMAGE} should point to the CC singularity image created when running the CC setup script (see \hyperref[Protocols_Methods]{Methods} 1.iii), usually located in \textit{\$HOME/chemical\_checker/cc.simg}, \textit{\$HOME} being the user’s home directory.
    \item \textit{CC\_REPO} should point to the \textit{chemical\_checker} directory inside \textit{PATH\_TO\_CC} (i.e., \textit{PATH\_TO\_CC/chemical\_checker}, see \hyperref[Protocols_Methods]{Methods} 1.ii and 1.iii).
    \item \textit{CC\_TMP} should point to a local directory, defined and created by the user, where CC outcome files will be stored. This directory is referred to as \textit{PATH\_TO\_CC\_TMP}.
\end{itemize}

v) Cloning the CC protocols repository to a local directory referred to as \textit{PATH\_TO\_CC\_PROTOCOLS}. This repository includes all the notebooks necessary to implement the analyses presented in this manuscript. \\

\begin{lstlisting}
mkdir -p <PATH_TO_CC_PROTOCOLS> && cd <PATH_TO_CC_PROTOCOLS>
git clone http://gitlabsbnb.irbbarcelona.org/packages/protocols.git
\end{lstlisting}

In brief, the repository contains four Python notebooks corresponding to the four tasks implemented herein, along with the links to the raw bioactivity data required to build the new CC spaces, located in Zenodo repositories. The following points in this section provide an overview of the individual steps needed to generate new CC spaces and signatures.

% \paragraph{2. Gathering bioactivity data} \leavevmode

% To calculate type III signatures for any compound set of interest, it is necessary to collect all preexisting type II signatures (from other CC spaces) in a custom directory (from now on called \textit{custom\_path}). Such data can be directly downloaded from \href{https://chemicalchecker.com/downloads/signature2}{https://chemicalchecker.com/downloads/signature2}. For further details on the generation of type III signatures, please see \hyperref[Overview of the Chemical Checker data integration pipeline]{Overview of the Chemical Checker data integration pipeline}.


\paragraph{2. Running a Jupyter Notebook with the CC image} \leavevmode

We run a Jupyter Notebook in the CC protocols directory within the previously built CC image by executing the following command (which is an alias to run the \textit{setup/run\_chemicalchecker.sh} file from the cloned CC repository): \\

\begin{lstlisting}
source ~/.bashrc
cd <PATH_TO_CC_PROTOCOLS>
chemcheck -d <PATH_TO_CC>/chemical_checker/package -c <PATH_TO_CC_CONFIG>
\end{lstlisting}

All notebooks needed to build the four spaces described in this manuscript are found in \textit{PATH\_TO\_CC\_PROTOCOLS/protocols/notebooks}.

Once the Jupyter Notebook is up and running, it is essential to import the CC package itself as well as all necessary external libraries to run the analyses (e.g. numpy). Before that, we also need to point the environment variable \textit{CC\_CONFIG} to the local CC configuration file (see \hyperref[Protocols_Methods]{Methods} 1.iv). In addition and, after importing the CC package, we can specify the level of log outputs printed along the procedure. This piece of code is already included in all the exemplary notebooks. \\

\begin{lstlisting}
os.environ['CC_CONFIG'] = '/aloy/home/acomajuncosa/cc_config.json'  # Modify path at will
from chemicalchecker import ChemicalChecker
ChemicalChecker.set_verbosity('DEBUG') # CRITICAL, ERROR, WARN, INFO or DEBUG
\end{lstlisting}

\paragraph{3. Gathering CC data} \leavevmode

To successfully implement all CC functionalities illustrated in this work, the user needs to gather the CC bioactivity data from our web servers (e.g. type II signatures, see \hyperref[Protocols_Methods]{Methods} 9). To illustrate the downloading process, we provide exemplary code that programmatically downloads the CC signatures, although the user can download individual files containing bioactivity signatures manually (\textit{https://chemicalchecker.org/downloads/signatureX}, X being 0, 1, 2 or 3). In brief, data are first downloaded in a compressed tar.gz format and then uncompressed in the directory \textit{PATH\_TO\_DATA}, as shown in the notebook Download\_Data.ipynb included in the CC protocols repository (see code below). Since the CC is subject to yearly-carried updates, the size of the downloaded files may increase, as does the amount of publicly released bioactivity data. As of October 2024, the overall process takes 15 minutes to download and 30 minutes to decompress, requiring around 65 GB of free disk space and a stable wired internet connection (e.g. Ethernet). For further details on what specific CC data are needed to implement each CC functionality, please see the \hyperref[Supplementary_Protocols_DownloadingData]{Supplementary Information}.  \\

\begin{lstlisting}
import tarfile
import wget
import os

# Modify PATH at will
PATH_TO_OUTPUT = "/aloy/home/acomajuncosa/CC_DATA"

# Create path
os.makedirs(PATH_TO_OUTPUT, exist_ok=True)

# Download data
def download_data(PATH_TO_OUTPUT):
    os.chdir(PATH_TO_OUTPUT)
    wget.download("https://chemicalchecker.com/api/db/getFile/root/sign_links.tar.gz/", out=PATH_TO_OUTPUT )

download_data(PATH_TO_OUTPUT)

# Uncompress data
def decompress_data(PATH_TO_FILE, PATH_TO_DATA):
    os.makedirs(PATH_TO_DATA, exist_ok=True)
    with tarfile.open(PATH_TO_FILE, "r:gz") as tar:
        tar.extractall(path=PATH_TO_DATA)

# Modify PATHS at will
PATH_TO_FILE = "/aloy/home/acomajuncosa/CC_DATA/sign_links.tar.gz"
PATH_TO_DATA = "/aloy/home/acomajuncosa/CC_DATA/DATA"
decompress_data(PATH_TO_FILE, PATH_TO_DATA)
\end{lstlisting}

\paragraph{4. Creating a CC instance} \leavevmode

A new CC instance is created with the directory chosen to allocate the results (\textit{local\_cc\_dir}). Additionally, we also need to specify the location of existing CC data (\textit{PATH\_TO\_DATA}). \\

\begin{lstlisting}
local_cc_dir = '../local_CC_M1'  # Modify at will
PATH_TO_DATA = "/aloy/home/acomajuncosa/CC_DATA/DATA/"  # Modify at will
cc_local = ChemicalChecker(local_cc_dir, dbconnect=False, custom_data_path=PATH_TO_DATA)
\end{lstlisting}

The typical CC folder architecture will be created inside \textit{local\_cc\_dir}. The \textit{full} directory will contain the computed signatures (from 0 to III) for the corresponding small molecules, while the \textit{reference} set will include a non-redundant subset of the data, computed using the distance matrix among all compounds.

\paragraph{5. Loading raw data} \leavevmode

To start the signaturization process, we first need to load a preprocessed version of the raw bioactivity data. Depending on the format of the data, the loading process may differ significantly. In the provided examples (Tasks 1-4), we have included cases in which the data is located in a CSV file and in a H5 file (see the code below for loading the input CSV data file for the new M1.001 space). Essentially, the starting data must consist in a well-defined bioactivity matrix (e.g. a pandas dataframe) containing N compounds (rows, indices) and M biological features (columns). Note that the code needs to be adapted in case of using user-defined data. For all the examples presented in this manuscript, we also provide the code to download the data from our online repository and store it in the corresponding data directory (not shown here) to be then loaded (shown below). \\ 

\begin{lstlisting}
inputFile="../data/M1/microbiota_raw.csv"  # Modify at will
df=pd.read_csv(inputFile,index_col=0)
\end{lstlisting} 


\paragraph{6. Generating type 0 signatures} \leavevmode

Once the bioactivity data are loaded, we can generate type 0 signatures with the following code block. It is important to mention that we first need to define a \textit{dataset} name in a particular format specifying the CC space the data will be dumped in (e.g. M1.001, please see the \hyperref[Building_NEW_CC_BIOACTIVITY_SPACES]{Building new Chemical Checker bioactivity spaces} section). For further information about the generation of type 0 signatures, please see \hyperref[Overview of the Chemical Checker data integration pipeline]{Overview of the Chemical Checker data integration pipeline}. \\

\begin{lstlisting}
dataset = 'M1.001'  # e.g. B1.002, D1.002, D6.001, M1.001
sign0 = cc_local.signature(dataset, 'sign0')
sign0.clear_all()
sign0.fit(X=df.values, keys=list(df.index), features=list(df.columns))
\end{lstlisting}


\paragraph{7. Generating type I signatures} \leavevmode

After obtaining type 0 signatures, we proceed to the generation of type I signatures. The code is straightforward and analogous to the previous step. Additionally, we also need to precompute compound nearest neighbors at type I signature level. For further information about the generation of type I signatures and the calculation of neighbors, please see \hyperref[Overview of the Chemical Checker data integration pipeline]{Overview of the Chemical Checker data integration pipeline}. \\

\begin{lstlisting}
sign0 = cc_local.signature(dataset, 'sign0')
sign1 = cc_local.signature(dataset, 'sign1')
sign1.clear_all()
sign1.fit(sign0)

sign1 = cc_local.signature(dataset, 'sign1')
neig1 = cc_local.get_signature("neig1", "full", dataset)
neig1.clear_all()
neig1.fit(sign1)
\end{lstlisting}

\paragraph{8. Generating type II signatures} \leavevmode

Once we have type I signatures and neighbors calculated for our compound set, we can proceed to the generation of type II signatures. As seen in previous steps, the code is straightforward and follows the same architecture as before. For further information about the generation of type II signatures, please see \hyperref[Overview of the Chemical Checker data integration pipeline]{Overview of the Chemical Checker data integration pipeline}. \\

\begin{lstlisting}
sign1 = cc_local.get_signature('sign1', 'full', dataset)
neig1 = cc_local.get_signature('neig1', 'full', dataset)
sign2 = cc_local.signature(dataset, 'sign2')
sign2.clear_all()
sign2.fit(sign1, neig1, oos_predictor=False)
\end{lstlisting}


\paragraph{9. Generating type III signatures} \leavevmode

The last step in the signaturization process is the calculation of type III signatures. We first collect all type II signatures from the existing CC spaces along with type I and type II signatures for the extended or newly created space. Since the calculation of type III signatures is computationally expensive, we run it on an HPC cluster to enable CPU parallelization or GPU computing. Indeed, we encourage users to run the generation of type III signatures in their own HPC cluster. Otherwise, it can be run locally in the same manner that previous steps, although the overall calculation may take longer to complete. Additionally, when creating a new CC space, it is important to check the overlap between the input dataset and the CC universe of small molecules, as poor overlaps between both sets may eventually result in unreliable type III signatures. Furthermore, chemical signatures (A1, A3, A4 and A5) are automatically calculated for all those compounds that are not included within the CC universe (\textit{complete\_universe='fast'}). If the user also wants to include A2 signatures, a particularly slow process due to the generation of 3D conformers, the \textit{complete\_universe} parameter needs to be set to \textit{'full'}. Finally, we encourage the user to provide the corresponding mappings between the input InChIKeys and the molecule InChIs in a Python dictionary. Otherwise, the pipeline will query online repositories (e.g. PubChem) to derive the mappings, which may significantly slow down the entire process. The code below corresponds to the case example from Task 4 (M1.001) and it needs to be adapted to every particular exercise. For additional examples, please see our \href{https://gitlabsbnb.irbbarcelona.org/packages/protocols}{Gitlab repository}. \\

\begin{lstlisting}
# CHECK OVERLAP

# Dataset Name
dataset = 'M1.001'

# Get CC universe
cc_universe = []
for dat in cc_local.datasets:
    if dat != dataset and dat.endswith('001'):
        cc_universe.extend(cc_local.get_signature('sign2', 'full', dat).keys)
cc_universe = set(cc_universe)

# Get sign2
sign2 = cc_local.signature(dataset, 'sign2')

# Get M1 molecules
m1_molecules = set(sign2.keys)

print("Number of molecules in the CC universe: " + str(len(cc_universe))) # 1009293
print("Number of molecules in M1 sign2: " + str(len(m1_molecules))) # 200
print("Intersection CC & M1: " + str(len(cc_universe.intersection(m1_molecules)))) # 188

# GET DATA

# Instantiation of sign3
sign3 = cc_local.signature(dataset, 'sign3')
sign3.clear_all()

# Create a list of sign2 to feed sign3 -- using the 25 CC spaces & M1
sign2_list = list()

# For each CC space
for ds in cc_local.coordinates:
    ds += '.001'
    sign2_list.append(cc_local.get_signature('sign2', 'full', ds))

# Append the new M1 space
sign2_list.append(cc_local.get_signature('sign2','full', dataset))

# In total, we now have 26 spaces
print(len(sign2_list)) # 26

# Get M1 sign1
sign1_self = cc_local.signature(dataset, 'sign1')

# Get M1 sign2
sign2_self = cc_local.signature(dataset, 'sign2')

# FIT SIGN3

mapp = None
""" 
# Alternatively, you can provide your in-house python dictionary to map InchiKey's to InChI's (see example below)
mapp = { 
'LPXQRXLUHJKZIE-UHFFFAOYSA-N': 'InChI=1S/C4H4N6O/c5-4-6-2-1(3(11)7-4)8-10-9-2/h(H4,5,6,7,8,9,10,11)',
'BZKPWHYZMXOIDC-UHFFFAOYSA-N': 'InChI=1S/C4H6N4O3S2/c1-2(9)6-3-7-8-4(12-3)13(5,10)11/h1H3,(H2,5,10,11)(H,6,7,9)',
'XZWYZXLIPXDOLR-UHFFFAOYSA-N': 'InChI=1S/C4H11N5/c1-9(2)4(7)8-3(5)6/h1-2H3,(H5,5,6,7,8)'
} 
"""

# CAUTION: COMPUTATIONALLY DEMANDING STEP - Consider running it in an HPC cluster
sign3.fit(sign2_list, sign2_self, sign1_self, sign2_universe=None, complete_universe="fast", sign2_coverage=None, dbconnect=False, mapping_dict=mapp)
\end{lstlisting}


\paragraph{10. Generating diagnosis plots} \leavevmode

Finally, to visualize the flow of the data along the integration pipeline, we can generate diagnosis plots for all the newly obtained signatures (0, I, II and III) with the code provided below (replacing X by 0, 1, 2 or 3, depending on the signature type under analysis). For further information about the generation and interpretation of diagnosis plots, please see the \hyperref[Protocols_SupplementaryInformation]{Supplementary Information}. \\

\begin{lstlisting}
signX = cc_local.signature(dataset, 'signX')
diagX = sign.diagnosis(ref_cctype='sign0')
diagX.canvas(size='small', savefig=True, savefig_kwargs={'dpi': 300})
\end{lstlisting}
