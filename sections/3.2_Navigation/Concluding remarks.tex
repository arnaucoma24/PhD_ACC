\subsection{Concluding remarks}


The representation of small molecules in the shape of high-dimensional vectors constitutes the starting point of many computational drug discovery approaches \cite{cereto-massague_molecular_2015}. Although most of these representations are interpretable, informative and easy to use, some of their features may be highly redundant or mostly uninformative. In addition, the graphical representation of abstract high-dimensional points is practically unfeasible for human interpretation, which limits quantitative analysis to the calculation of distances between them.

Although a significant fraction of the encoded information may be partially lost during the process, dimensionality reduction techniques are invaluable for data simplification, compression, and for the generation of 2D visualizations aimed at qualitative analyses. Methods such as PCA, t-SNE and UMAP are commonly used, each having its own advantages and drawbacks. t-SNE is particularly well suited to preserve the local structure of high-dimensional data when projecting it to a bidimensional space and is effective at modeling non-linear relationships within the data. However, its inability to retain the global structure of the data, along with its high computational cost, can make it less suitable compared to other, more efficient approaches, mentioned above.

Indeed, the 2D visualization of several diverse libraries of chemical compounds revealed interesting findings. Overall, our analyses highlighted the significant lack of overlap in terms of chemical features and properties between synthetic small molecules, biologically tested compounds and marketed drugs (IRB Library aka Chemically Diverse library, the Chemical Checker and RepoHub, respectively), compared to compounds extracted from nature (Medina, Metabolights and CMAUP). This emphasizes the need to integrate both approaches in the context of drug discovery, in order to maximize the probability of finding novel and useful therapeutic agents (i.e. chemical compounds).

However, in many cases, such libraries are growing exponentially, sometimes reaching sizes that make experimental testing infeasible. Efficient sampling and selection strategies are thus essential to identify smaller but representative subsets of compounds that ideally retain the overall chemical diversity and potential biological relevance of the original, huge set. A random selection of compounds would tend to overrepresent highly populated areas of the chemical space, potentially overlooking other, less populated but biologically promising regions. To address this, we implemented a clustering procedure aimed at homogeneously representing different regions of the chemical space. Indeed, our approach involved the selection of representative compounds from both densely populated and sparse regions, providing a more balanced sampling of the chemical space.

Finally, although the small molecule similarity principle has guided Medicinal Chemistry efforts for decades, the growing wealth of biological data associated with chemical compounds has uncovered relationships between them that extend beyond their mere structure and chemical properties. In fact, as biological complexity increases, the link between chemical structure and bioactivity becomes more blurred. The use of diverse bioactiviy data may thus provide a more holistic and therapeutically relevant perspective on the effect of chemical compounds in biological systems. In this work, we have shown how bioactivity signatures built upon inferring protein binding profiles reveal relationships between small molecules even in the absence of chemical similarity. These results, rather than underrating the value of classical chemically-based approaches, underscore the need to integrate them with novel, bioactivity data-driven strategies. 





